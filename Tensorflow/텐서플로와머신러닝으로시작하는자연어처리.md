## 텐서플로와 머신러닝으로 시작하는 자연어처리

-로지스틱 회귀부터 트랜스포머 챗봇까지



#### 2. 자연어 처리 개발 준비



#### tf.data

머신러닝에서 문제를 해결할 때 많은 시간이 데이터를 다루는 데 소용된다.

데이터 분석, 전처리, 파이프 라인을 만드는 과정에서 약 70~80%의 시간을 소비한다고 해도 과언이 아니다.

GPU가 병목현상 없이 효율적으로 데이터를 처리할 수 있게 최적화를 지원한다.

tf.data는 다양한 데이터 접근 방식이 존재한다. 그중 하나인 사용법이 직관적인 tf.data.Dataset.from_tensor_slinces를 채택하여 사용한다.

```python
import os
import tensorflow as tf
import numpy as np

from tensorflow.keras import preprocessing

samples = ['너 오늘 이뻐보인다',
          '나는 오늘 기분이 더러워',
          '끝내주는데, 좋은 일이 있나봐',
          '나 좋은 일이 생겼어',
          '환상적인데, 정말 좋은 것 같아']
label = [[1],[0],[1],[1],[0],[1]]

tokenizer = preprocessing.text.Tokenizer() # 객체 생성
tokenizer.fit_on_texts(samples) # 시퀀스 (딕셔너리) 생성 : 사전이 될 매핑이 된 딕셔너리
sequences = tokenizer.texts_to_sequences(samples) # 데이터 담기

word_index = tokenizer.word_index # 숫자로 바뀐 데이터

print('수치화된 텍스트 데이터 : \n',sequences)
print('각 단어의 인덱스 : \n',word_index)
print('라벨 :',label)
```

```
수치화된 텍스트 데이터 :
[[4 1 5 6]
[7 1 8 9 ]
...
[17 18 19 20]]
각 단어의 인덱스 :
{'오늘' : 1, '좋은' : 2, '일이':3, ... '좋은거' : 19, '같아':20}
라벨 : [[1],[0],[1],[1],[0],[1]]
```



시퀀스로 수치화시킨 데이터와 레이블을 한세트로 묶어 tf.data를 활용해 처리해보자.

```python
dataset = tf.data.Dataset.from_tensor_slices((sequences,label))
iterator = dataset.make_one_shot_iterator()
next_data =iterator.get_next()
```

* tf.data.Dataset.from_tensor_slices() : 주어진 데이터 x,y를 묶어서 조각으로 만들고 함께 쓸수있게 해준다.
* make_one_shot_iterator() : 데이터를 하나씩 사용할 수 있게 만든다. 데이터는 이터레이터 형식으로 정의된다.
* get_next() : 이터레이터의 함수로 데이터가 하나씩 나오게 되는 구조다.

한번 next_data 객체를 이용해서 세션을 실행하고 계속 불러오자

```python
with tf.Session() as sess:
    while True:
        try:
            print(sess.run(next_data))
        except tf.errors.OutOfRangeError:
            break
```

* 배치사이즈로 묶기

```python
BATCH_SIZE = 2 # 배치사이즈
dataset = tf.data.Dataset.from_tensor_slices((sequences, label))
dataset = dataset.batch(BATCH_SIZE) # batch() 함수로 원하는 배치사이즈 만큼의 인자를 받아 묶을 수 있다. 
iterator = dataset.make_one_shot_iterator()
next_data = iterator.get_next()

with tf.Session() as sess:
    while True:
        try:
            print(sess.run(next_data))
        except tf.errors.OutOfRangeError:
            break
```

* 데이터를 셔플하기

```python
dataset = tf.data.Dataset.from_tensor_slices((sequences, label))
dataset = dataset.shuffle(len(sequences)) # shuffle() 함수를 적용할 때 인자 값으로 데이터의 전체 길이를 넣으면 된다. 
iterator = dataset.make_one_shot_iterator()
next_data = iterator.get_next()

with tf.Session() as sess:
	while True:
		try:
            print(sess.run(next_data))
        except tf.errors.OutOfRangeError:
            break
```

* 에폭 설정하기(전체 데이터를 몇번 사용하는지를 설정하기)

```python
EPOCH = 2

dataset = tf.data.Dataset.from_tensor_slices((sequences,label))
dataset = dataset.repeat(EPOCH) # repeat() 함수에 인지값에 epoch값을 넣어준다.
iteraotr = dataset.make_one_shot_iterator()
next_data = iterator.get_next()
with tf.Session() as sess:
	while True:
        try:
            print(sess.run(next_data))
        except tf.errors.OutOf RangeError:
            break
```

* 모델에 따라 입력값이 하나가 아니라 두개 이상이 될 수도 있는데, 이 때 라벨을 제외한 나머지 데이터를 하나의 입력값으로 묶기 위해 매핑 과정을 거친다.

1. 하나의 입력값을 딕셔너리에 넣기

```python
def mapping_fn(X,Y=None):
    input = {'x':X}
    label = Y
    return input, label

dataset = tf.data.Dataset.from_tensor_slices((sequences,label))
dataset = dataset.map(mapping_fn)
iterator = dataset.make_one_shot_iterator()
next_data = iterator.get_next()

with tf.Session() as sess:
    while True:
        try:
            print(sess.run(next_data))
        except tf.error.OutOfRangeError:
            break
```

2. 두개의 입력값을 딕셔너리에 넣기

```python
def mapping_fn(X1,X2,Y=None):
    input = {'x1':X1,'x2':X2}
    label = Y
    return input, label
```



* 배치, 셔플, 반복, 매핑 과정을 하나로 묶어서 사용하는 과정

```python
BATCH_SIZE = 2
EPOCH = 2

def mapping_fn(X, Y=None):
    input = {'x':X}
    label = X
    return input, label

dataset = tf.data.Dataset.from_tensor_slices((sequences,label))
dataset = dataset.map(mapping_fn)
dataset = dataset.shuffle(len(sequences))
dataset = dataset.batch(BATCH_SIZE)
dataset = dataset.repeat(EPOCH)
iterator = dataset.make_one_shot_iterator()
next_data = iterator.get_next()

with tf.Session() as sess:
    while True:
        try:
            print(sess.run(next_data))
        except tf.errors.OutOfRangeError:
            break
```





