## 케라스 창시자에게 배우는 딥러닝

### 1,2장

mnist 데이터셋은 넘파이 배열 형태로 케라스에 이미 포함되어 있음.불러 올때는, 

from keras.datasets import mnist

(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()

로 불러온다.

모델은 간단히 

from keras import models

from keras import layers

net = models.Sequential()

net.add(layers.Dense(512, activation=’relu’, input_shape=(28 * 28,)))

net_add(layers.Dense(10, activation=’softmax’))

로 구현하고 

손실 함수, 옵티마이저, 모니터링 지표를 넣어 컴파일한다.

network.compile(optimizer=’rmsprop’,

​			loss = ‘categorical_crossentropy’,

​			metrics=[‘accuracy’])

train_images = train_images.reshape((60000,28 * 28))

train_images = train_images.astype(‘float32’) / 255

test_images = test_images.reshape((60000, 28 * 28))

test_images = test_images.astype(‘float32’) / 255

으로 데이터 형식을 바꿔준다.

from keras.utils import to_categorical

train_labels = to_categorical(train_labels)

test_labels = to_categorical(test_labels)

로 레이블을 바이너리 형식으로 변환한다.

그리고 net.fit(train_images, train_labels, epochs=5, batch_size = 128)

로 학습한다.

결과를 평가할 땐,

test_loss, test_acc = net.evaluate(test_images, test_labels)

해서 학습한 네트워크의 손실과 정확도를 평가할 수 있다.



1차원 배열을 벡터, 2차원 배열을 행렬, 3차원이상의 배열을 텐서라고 한다.

보는 법은 제일 뒤의 shape가 가장 안쪽의 배열을 구성하는 개수로 차례대로 바깥쪽의 배열을 구성하는 shape가 된다.

데이터 타입은 대개 float32, float64, int32등등을 사용한다. 

간혹 char을 사용하기도 한다.

딥러닝에서 사용하는 모든 데이터 텐서의 첫번 째 shape는 샘플 축이다. 그러므로 

batch = train_images[:128]

로 배치를 지정할 수 있고,

다음 배치는

batch = train_images[128:256] 이런식이 된다.

n 번째 배치는 

batch = train_images[128 * n : 128 * (n+1)]

으로 표현할 수 있다.

이미지 데이터 shape은 텐서플로의 경우, (batch_size, height, width, channel)로 구성된다.

theano는 (batch_size , channel, height, width)로 구성된다.

케라스는 백엔드(텐서플로, 씨아노) 를 어떤 걸로 쓰는지에 따라 다르다.

 ```python
def naive_relu(x):
	assert len(x.shape) ==2
	x = x.copy()  # 값 복사
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i , j] = max(x[i, j], 0)
	return x
 ```



브로드 캐스팅(중요하다)

브로드캐스팅은 2단계가 있다.

1. 큰 텐서의 차원에 맞도록 작은 텐서에 축이 추가된다.
2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다.

브로드캐스팅의 예는 다음과 같다.

```python
import numpy as np

x = np.random.random((64, 3, 32, 10))
y = np.random.random((32, 10))
z = np.maximum(x, y)
```

\# 출력 텐서의 크기 ( 64, 3, 32, 10)

점곱 연산은 다음과 같이 나타낼 수 있다.

```python
import numpy as np

z = np.dot(x, y)
z = x * y
```

계산 하는 방식은

```python
def naive_vector_dot(x, y):
	assert len(x.shape) == 1
	assert len(y.shape) == 1
	assert x.shape[0] == y.shape[0]
	z = 0.
	for i in range(x.shape[0]):
		z+=x[i] * y[i]
	return z
```



두 벡터의 점곱은 스칼라가 되므로, 원소 개수가 같은 벡터끼리 점곱이 가능하다.

행렬 간의 점곱은

```python
def naive_vector_dot(x, y):
	assert len(x.shape) == 2
	assert len(y.shape) == 2
	assert x.shape[1] == y.shape[0]
	z = np.zeros((x.shape[0], y.shape[1]))
	for i in range(x.shape[0]):
		for j in range(y.shape[1]):
			row_x = x[i, :]
			column_y = y[:, j]
			z[i, j] = naive_vector_dot(row_x, column_y)
	return z
```



의 식으로 나타낼 수 있다.

affine 변환, 회전, 스케일링은 점곱을 통해 구현이 가능하다.



훈련 과정

1. 훈련 샘플 x와 타깃 y의 배치를 추출
2. x를 사용하여 네트워크를 실행(forward pass단계), 예측 y_pred를 구한다.
3. y_pred와 y_true의 차이를 측정하여 이 배치에 대한 네트워크의 손실을 계산한다,
4. 배치에 대한 손실이 조금 감소되도록 네트워크의 모든 가중치를 업데이트 한다.

최적화 방법 중 SGD의 변종이 있는데,

모멘텀을 사용한 SGD, Adagrad, RMSProp등이 있다.

모멘텀은 SGD에 있는 2개의 문제점인 수렴 속도와 지역 최솟값을 해결한다.

지역 최솟값에 갇히지 않도록 과거의 가속도를 함께 고려하여 현재 단계의 최적화를 수행한다.

```
past_velocity = 0.

momentum = 0.1

while loss > 0.01:

​	w, loss, gradient = get_current_parameters()

​	velocity = momentum * past_velocity - learning_rate * gradient

​	w = w + momentum * velocity - learning_rate * gradient

​	past_velocity = velocity

​	update_parameter(w)
```



위는 단순한 구현의 예이다.



mnist 예제를 다시 살펴보면,

이미지를 reshape함수로 (60000, 784)의 크기로 변환하고,

float32타입으로 변환한다.

간단한 신경망을 구성하고, 마지막 레이어는 softmax로 확률값이 출력되도록 한다,

그리고 옵티마이저와 손실함수, 측정지표를 매개변수로 컴파일하고, 

에폭과 배치사이즈를 지정하여 image와 label을 인풋으로 학습한다,



학습은 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화 하는 모델 파라미터의 조합을 찾는 것을 의미한다. 

배치를 기준으로 손실을 구하고, 그에 상응하는 그래디언트로 학습한다. 

네트워크의 파라미터는 그래디언트의 반대 방향으로 조금씩 움직인다.

체인룰을 이용해 역전파를 쉽게 한다.

손실은 훈련하는 동안 최소화해야할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용한다.

문제 해결 상황에 따라 다른 손실함수를 사용한다.

옵티마이저는 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의한다.

 ### 3장

#### 3.1 신경망의 구조

네트워크를 구성하는 층
입력 데이터와 그에 상응하는 타깃
학습에 사용할 피드백 신호를 정의하는 손실 함수
학습 진행 방식을 결정하는 옵티마이저

#### 3.1.1 층: 딥러닝의 구성 단위

층 : 하나 이상의 텐서를 입력으로 받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈
완전 연결층(fully connected layer)과 밀집 층(dense layer)에 의해 처리되는 경우가 많다.
(samples, timestamps, features)의 3D 텐서는 주로 LSTM의 RNN으로 처리되는 경우가 많고, (samples, height, width, channels)와 같은 4D 텐서는 주로 CNN으로 처리 되는 경우가 많다.

 #### 3.1.2 모델: 층의 네트워크

모델 : 층을 순서대로 쌓은 비순환 유향 그래프
머신러닝 : 가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것
텐서 연산을 통해 모델의 가중치 텐서들이 적합한 가중치를 찾아가는 것이 목표.



#### 3.1.3 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠

손실 함수 또는 목적함수 : 훈련하는 동안 최소화가 될 값
옵티마이저 : 손실 함수를 기반으로 네트워크가 어떻게 업데이트 될지 결정하는 방법
손실 함수를 제대로 선택해야만, 원하는 목적에 다다를 수 있는 모델이 완성될 수 있다. 
일반적으로, 2개의 클래스 분류 문제는 binary crossentropy, 다중 클래스 분류 문제에는 categorical crossentropy, 회귀 문제에는 평균제곱오차, 시퀀스 학습 문제에는 connection temporal classification등을 사용한다. 



#### 3.2 케라스 소개

https://keras.io
MIT 라이센스
2.7~3.6 파이썬과 호환가능



#### 3.2.1 케라스, 텐서플로, 씨아노, CNTK

백엔드 엔진으로 tensorflow, theano, CNTK 를 지원



#### 3.2.2 케라스를 사용한 개발: 빠르게 둘러보기

케라스에서 모델을 정의하는 방법 2가지
1. Sequential 클래스(층을 순서대로 쌓아올린 네트워크)
2. 함수형 API(완전히 임의의 구조를 만들 수 있는 비순환 유향그래프)
3. 

#### 3.3 딥러닝 컴퓨터 셋팅

윈도우와 CPU환경에서 케라스를 사용할 수 는 있지만 되도록 우분투와 GPU환경을 구축한 후 사용을 권장함.



#### 3.3.1 주피터 노트북: 딥러닝 실험을 위한 최적의 방법

주피터 노트북 : 긴 코드를 작게 쪼개 독립적으로 실행가능한 편집기
개인적인 경험으로, 튜토리얼을 익힐 때 로컬 컴퓨터에서 디버깅 속도가 빠르고 수정이 편리하기 때문에, 처음 접하는 도메인에서 기본 튜토리얼을 통해 실력을 향상시킬 때 도움을 많이 주는 툴이라고 생각합니다.



#### 3.3.2 케라스 시작하기: 두 가지 방법

1. aws EC2에서 주피터노트북으로 케라스를 사용할 수 있음
2. 로컬에서 환경 설정 후 사용



#### 3.3.3 클라우드에서 딥러닝 작업을 수행했을 때 장단점

딥러닝 파워 유저가 되기 위해서는 GPU는 필수



#### 3.3.4 어떤 GPU 카드가 딥러닝에 최적일까?

현재 최고 성능의 그래픽 카드는 Quadro rtx 6000이 압도적으로 우수한 성능을 보여주고, 
그 다음으로 rtx 2080 ti와 Titan V CEO edition이 나란히 2위의 성능을 보여주고 있음.
개인용 컴퓨터에서 장착 사용 가능한 가격대의 GPU는 rtx 2080 ti가 최고의 성능을 보여주고 있음.



#### 3.4 영화 리뷰 분류: 이진 분류 예제

#### 3.4.1 IMDB 데이터셋

IMDB 데이터셋 train data 2만 5000개, test data 2만 5000개로 나누어져 있음
50% 긍정, 50% 부정으로 구성

```python
from keras.datasets import imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)
```

위의 방식으로 로드가 가능하다.

```python
train_data[0]
>>>[1, 14, 22, 16, ..., 178, 32]
train_labels[0]
>>>1
```

데이터는 단어 시퀀스가 인코딩 된 숫자 데이터가 리스트로 나열되어있고 레이블은 1과 0의 긍부정으로 구성되어 있다.
단어를 확인하고 싶다면, 디코딩하는 과정을 거쳐 검증하면 된다.



#### 3.4.2 데이터 준비

신경망에 숫자 리스트는 주입할 수 없다.
따라서 리스트를 텐서로 변환해야하는데 2가지 방법으로 할 수 있다.
1. 같은 길이가 되도록 리스트에 패딩을 추가하고 (samples, squence_length)크기의 정수 텐서로 변환한다. 그 다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용한다.
2. 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환한다.=>[3,5]의 위치는 1의 값, 나머지는 모두 0의 값을 가지는 n개 샘플차원의 벡터로 각각 변환하는 것. 그 다음 부동 소수 벡터 데이터를 다룰 수 있는 Dense층을 신경망의 첫 번째 층으로 사용한다.



#### 3.4.3 신경망 모델 만들기

입력데이터 : 벡터, 입력레이블 : 스칼라(0 또는 1)
이런 문제에는  Dense(16, activation='relu')을 쌓아올린 것
**중요 : 매개변수(16)은 은닉 유닛의 개수 -> 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 된다.
16개의 은닉 유닛이 있다는 것은 가중치 행렬 w의 크기가 (input_dimension, 16)이라는 뜻이다.
입력 데이터와 w를 점곱하면 입력 데이터가 16차원으로 표현된 공간으로 투영된다. 표현 공간의 차원을 쉽게 생각하면, 학습할 때의 자유도 즉 파라미터라고 생각하면 된다. 데이터를 분류하는 작업이 쉬울 경우 비교적 적은 차원이 알맞고, 데이터가 크고 복잡하며 분류할 클래스가 많을 경우에는 많은 차원이 알맞다. 오버피팅에 유의하여 파라미터를 조정할 필요가 있다.
Dense를 쌓을 때 두가지를 유의할 것
1. 얼마나 많은 층을 쌓을 것인가?
2. 각 층에 얼마나 많은 은닉 유닛을 둘 것인가?
  loss function은 binary crossentropy가 적합하고, mean_squared_error도 사용가능하다.
  optimizer는 rmsprop을 사용하는데, 안정적이고 좋은 성능을 보이는 알고리즘이므로 Adam, NAG와 더불어 많이 사용하는 optimizer다.

#### 3.4.4 훈련 검증

model.fit() 함수는 History 객체를 반환한다.
train 과정에서 발생하는 정보를 딕셔너리형태 history 속성으로 갖고 있다.
validation 셋을 사용하기 위해서는, 다음과 같은 형태로 학습을 진행하면 된다.

```python
history = model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_val,y_val))
history_dict = history.history
history_dict.keys()

>>>[u'acc', u'loss', u'val_acc', u'val_loss']
```

성능 비교를 위해 이부분은 꼭 기억할 것!
matplotlib 모듈로 시각화 하기 위해서,

```python
import matplotlib.pyplot as plt
history_dict = histroy.history
loss = history_dict['loss']
val_loss = history_dict['val_loss']
epochs = range(1, len(loss) +1)
plt.plot(epochs, loss, 'bo', label= 'Training loss') --- bo는 파란색 점을 의미
plt.plot(epochs, val_loss, 'b', label='Validation loss') ---- b는 파란색 실선을 의미
plt.title('Training & Val loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.show()
```



#### 3.4.5 훈련된 모델로 새로운 데이터에 대해 예측하기

모델을 훈련시킨 후 model.predict(x_test)로 확률을 예측할 수 있다.

```python
model.predict(x_test)
array([ [0.98006207]
		[0.99758697]
		[0.99975556]
		...,
		[0.82167041]
		[0.02885115]],dtype=flaot32)
```



이런 결과가 나올 경우, 어떤 샘플에 대해서는 0.98 이상의 높은 확률값으로 예측하고 있지만, 어떤 샘플에 대해서는 0.02처럼 확신이 부족한 예측을 보인다고 해석할 수 있다.



#### 3.5 뉴스 기사 분류: 다중 분류 문제

로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류 하는 문제
정확히 말하면, single-label, multiclass classification이 되고, 데이터 포인트가 여러개의 클래스에 속할 수 있다면, multi-label, multiclass classification 문제가 된다.



#### 3.5.1 로이터 데이터셋

로이터 데이터셋
1. 1986년 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합
2. 텍스트 분류를 위해 사용되는 간단한 데이터셋
3. 46개의 토픽이 있음
4. 토픽에 따른 데이터 수의 불균형이 있음.
5. 8982개의 train sample과 2246개의 test sample이 있음
6. IMDB 리뷰와 같이 정수리스트(단어 인덱스), 토픽 인덱스(0~45)



#### 3.5.2 데이터 준비

```python
import numpy as np

def vectorize_sequences(sequences, dimension=10000):
	results = np.zeros((len(sequences), dimension))
	for i, sequence in enumerate(sequences):
		results[i,sequences] = 1.
	return results
    
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)

```

원-핫 인코딩으로 벡터로 변환
레이블 데이터는 

```python
from keras.urils,.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
```


케라스 내장함수를 이용하여 카테고리 분류가 가능하다.



#### 3.5.3 모델 구성

IMDB 영화 리뷰는 클래스가 2개 였으므로, 은닛 유닛의 개수를 16개로 지정했지만, 46개의 클래스를 분류하는 로이터 토픽 분류에서는 은닉 유닛의 개수가 적을 경우, feature를 누락하는 info bottleneck 현상을 일으킬 우려가 많으므로, 64개의 유닛을 사용해보자.

```python
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
```

* optimizer : rmsprop
* loss function : categorical_crossentropy



#### 3.5.4 훈련 검증

10000개 중 1000개의 데이터를 validation data로 사용하여 학습



#### 3.5.5 새로운 데이터에 대해 예측하기

```python
predictions = model.predict(x_test)

```

* prediction의 각 항목은 길이가 46인 벡터
  (46, )
* 벡터들의 원소의 합은 1
  np.sum(predictions[0])
  1.0
* 가장 큰 값이 예측 클래스 -> 가장 높은 확률의 클래스
  np.argmax(prediction[0])
  3



#### 3.5.6 레이블과 손실을 다루는 다른 방법

* ##### 정수 레이블을 사용할 때 

* loss function -> sparse_categorical_crossentropy

  

* ##### 범주형 인코딩이 된 레이블을 사용할 때 

* loss function -> categorical_crossentropy



#### 3.5.7 충분히 큰 중간층을 두어야 하는 이유

마지막 출력이 46개의 클래스분류(차원)이므로 그 중간 층의 은닉 유닛은 46개보다 많이 적어서는 안된다. 

-> 중요 개념 : low level feature map을 확장시킬 때 정보 손실이 많이 발생하기 때문.



#### 3.6 주택 가격 예측: 회귀 문제

개별적인 레이블이 아닌 연속적인 값을 예측하는 문제 : 회귀(regression)
주의할 점 : logistic regression은 회귀가 아닌 분류 알고리즘!



#### 3.6.1 보스턴 주택 가격 데이터셋

보스턴 주택 가격 데이터셋
1. 1970년 중반 보스턴 외곽 지역의 범죄율, 지방세율 등의 데이터가 주어졌을 때 주택 가격의 중간 값을 예측하는 문제에서 사용하는 데이터 셋
2. 데이터 포인트 개수는 총 506개, train sample은 404개 , test sample은 102개
3. sample의 feature들은 스케일이 다름 (0~1, 1~12, 1~100)
4. 13개의 feature
5. label 데이터는 주택의 중간 가격(천달러 단위) 



#### 3.6.2 데이터 준비

스케일이 다른 feature들을 Scaling하는 작업이 필요함.
참고 : 
Scaling : 서로 다른 단위의 데이터를 같은 단위로 만들어서 큰 숫자가 더 중요해보이는 왜곡을 막는 것
Standardization : 분포를 평균 0, 표준편차 1로 바꾸는것
Normalization : 변수를 0과 1사이로 바꾸는것

```python
mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(axis=0)
train_data /= std
test_data -= mean
test_data /= std
```

* 절대 테스트 데이터에서 계산한 어떤 값도 사용해서는 안된다. 데이터 정규화처럼 간단한 작업도 !



#### 3.6.3 모델 구성

train 데이터가 적을수록 오버피팅이 잘 일어나기 때문에 작은 모델을 사용하는 것이 바람직
네트워크의 마지막 층은 활성화 함수가 없음 -> 선형 레이어(전형적인 스칼라 회귀를 위한 구성)
이 모델은 mse(mean squared error) loss function을 활용
평가 지표는 mae(mean absolute error)를 활용



#### 3.6.4 K-겹 검증을 사용한 훈련 검증

데이터 셋이 작으므로, 검증 데이터셋도 매우 작아짐
이럴 경우, K-fold cross-validation라고 불리는 방식으로 훈련을 진행함
K개의 분할(fold)로 데이터를 나누고 K-1개의 분할에서 훈련하고, 나머지 분할에서 평가하는 방법이다.
모델의 검증 점수는 K개의 검증 점수 평균





#### 4.1. 머신러닝의 분류

```
지도 학습, 비지도 학습, 자기 지도 학습, 강화학습
```



#### 4.1.1 지도학습

```
지도 학습 : 샘플 데이터와 샘플 데이터와 매칭되는 레이블 데이터로 학습하는 방법
```


지도학습은 다음과 같은 분야가 있다.

1. 분류
2. 회귀
3. 시퀀스 생성(sequence generation) : 이미지를 설명하는 캡션 생성
4. 구문 트리(syntax tree) 예측 : 문장이 주어지면 분해된 구문 트리 예측
5. 물체 감지(object detection) : 이미지에서 타깃의 bounding box 추정
6. 이미지 세분화(image segmentation) : 이미지에서 타깃을 픽셀단위로 예측하는 것 -> image classification과 image location을 보다 정확히 예측하는 작업



#### 4.1.2 비지도학습

```
비지도 학습 : 레이블링 없이 샘플 데이터만 갖고 학습하는 방법
```

데이터 시각화, 데이터 압축, 데이터의 노이즈 제거 또는 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용한다.
차원 축소(dimensionality reduction)와 군집(clustering)이 비지도 학습에서 잘 알려진 범주이다.



#### 4.1.3 자기지도학습

```
자기 지도 학습(self-supervised learning)은 지도 학습의 특별한 경우이지만, 별도의 범주로 할 만큼 충분히 차이점을 보인다.
```

자기 지도 학습은 사람이 만든 레이블을 학습에 사용하지 않는다.
학습 과정에 사람이 개입하지 않는 지도 학습이라고 볼 수 있다. 하지만, 학습은 정답(레이블)이 필요하므로, 알고리즘을 사용하여 샘플 데이터로부터 레이블을 만들어 학습한다.
예를 들어, autoencoder가 이에 속한다.
지난 프레임이 주어졌을 때, 다음 프레임을 예측하는 것이나, 이전 단어가 주어졌을 때 다음단어를 예측하는 것이 자기 지도 학습의 예이다.



#### 4.1.4 강화학습

```
강화학습 : 오래 전에 등장한 개념이지만, 잊혀졌다가 구글 딥마인드의 DQN 발표로 다시 부각된 학습 분야.
```

에이전트는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습된다.
게임 이외에 실제적인 성공사례는 아직 없다. 
하지만, 많은 애플리케이션을 대체할 것으로 보고 있다.
자율주행자동차, 자원 관리, 교육, 주식투자등이 있다.



#### 4.2 머신러닝 모델 평가

```
train , validate, test 의 3가지 절차로 머신러닝 모델의 학습부터 테스트가 이루어진다.
```

머신 러닝의 목표는 샘플 데이터에 대한 일반화된 높은 성능을 보이는 모델을 얻는 것이다.
그러므로, overfitting 문제를 피하기 위한 모델의 평가 방법이 중요하다.



#### 4.2.1 훈련, 검증, 테스트 세트

train, validate, test 3세트로 나누는 이유:
하이퍼파라미터에 따라 데이터에 대한 overfitting이 나오는 것을 validation set에서 확인이 가능하므로, 시간을 절약하고 모델의 설정을 튜닝 가능하다. 뿐만 아니라, validation set에 overfitting 된 모델을 마지막으로 test set에서 검증가능하므로, validation set에 정보가 많이 노출되는 information leak 현상을 완화시킬 수 있다.
데이터가 적을 때에는 학습할 수 있는 데이터가 적으므로, 

```
대표적으로 3가지의 방법으로 한정된 데이터셋을 활용해 overfitting 문제를 검증할 수 있다.
단순 홀드아웃 검증(hold-out validation), K-겹 교차 검증(K-fold cross-validation), 셔플링(shuffling)을 사용한 반복 K-겹 교차 검증( iterated K-fold cross-validation)이 있다. 
```

1. 단순 홀드아웃 검증(hold-out validation)
  데이터의 일정량을 validation 세트로 떼어 놓는다.
  이 평가 방법은 단순해서 , validation set과 test set이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할 수 있다.
2. K-겹 교차 검증(K-fold cross validation)
  데이터를 동일한 크기를 가진 K개 분할로 나눈다.
  각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련하고 분할 i에서 모델을 평가한다.  최종 점수는 이렇게 얻은 K개의 점수를 평균한다. 데이터 분할에 따라 편차가 클 때 도움이 되는 학습 방법이다. 
3. 셔플링을 사용한 K-겹 교차 검증(used shuffling K-fold cross validation)
  이 방법은 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할때 사용한다.
  캐글 경연에서는 이 방법이 아주 크게 동무이 된다.
  최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 되기 때문에 K*P개의 모델을 훈련하므로 비용이 매우 많이 든다.



#### 4.2.2 기억해야할 것

```
* 평가 방식을 선택할 때 유의 할 점

1. 대표성 있는 데이터
   클래스별 데이터 불균형을 최대한 줄이고,
   데이터의 순서를 셔플링한다.
2. 시간의 방향
   과거로부터 미래를 예측하고자 한다면, 데이터를 분할하기전에 무작위로 섞어서는 절대로 안된다.
   이렇게 하면 미래의 정보가 누설되기 때문이다.
   모델이 미래 데이터에서 훈련될 우려가 높기 때문이다.
3. 데이터 중복
   한 데이터 셋에 어떤 데이터 포인트가 두번 등장하면, train set과 validation set과 test set 데이터가 중복될 수 있다. 이로 인해 , train한 데이터를 test에 사용하는 경우가 생길 수 있다. 
```



#### 4.3 데이터 전처리, 특성 공학, 특성 학습

데이터 전처리와 특성 공학 기법은 특정 도메인에 종속적이다.



#### 4.3.1 신경망을 위한 데이터 전처리

```
벡터화 , 정규화, 누락된 값 다루기, 특성 추출
```

1. 벡터화(vectorization)
  모든 데이터는 모델의 입력을 위해 텐서로 변환해야 한다.
  예를 들어, 텍스트 분류 예에서 텍스트를 원-핫 인코딩을 사용해 정수 리스트로 변환했다.
2. 정규화(normalization)
  이미지 데이터의 경우 신경망에 입력하기 전, float32 타입으로 변경하고 255로 나누어 0~1사이의 부동 소수값으로 만든다.
  특성 별로 범위가 제각각 인 경우, 독립적인 standardization을 사용해, 평균이 0이고 표준편차가 1의 분포로 만들었다.
  균일하지 않은 데이터를 신경망에 넣는 것은 업데이트할 그래디언트를 커지게 해 신경망이 수렴하는 것을 방해한다.
  0~1사이의 값을 넣고, 모든 특성이 대체로 비슷한 범위를 가져야 한다.
3. 누락된 값 다루기
  신경망에서 0이 사전에 정의된 의미있는 값이 아니라면, 누락된 값을 0으로 입력해도 괜찮다.
  0이 누락된 데이터라는 것을 학습한다면, 이 값을 무시하기 시작할 것이다.
  테스트 데이터에서 누락된 값이 있을 가능성이 있다면, 누락된 값 없이 학습된 모델은 무시하지 못한다.
  그러므로, 누락된 값이 있는 훈련 데이터셋을 고의적으로 만들어 무시하는 법을 학습시켜야 한다.
4. 특성 추출
  모델이 수월하게 작업할 수 있는 어떤 방식으로 데이터가 표현될 필요성이 있다.
  예를 들어, 시계 이미지에서 시간을 알고자 한다면 
  원본 데이터는 2차원 픽셀 이미지 데이터이지만,
  더 나은 특성은 이미지에서 시계 바늘의 좌표가 될 것이고,
  보다 더 나은 특성은 시계 바늘의 각도가 될 것이다.



#### 4.3.2 특성 공학

```
특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만든다.
```

일반적으로 해당 문제를 아주 잘 이해하고 있어야 한다.
딥러닝은 대부분 특성 공학이 필요하지 않다.
그러나, 데이터의 수가 적을 경우 좋은 특성은 더욱 중요해지고, 성능에도 영향을 미칠 수 있으므로 신경을 쓰는 편이 좋다.



#### 4.4 과대적합과 과소적합

```
최적화 : 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정
일반화 : 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지
```

머신러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기다. 

모델이 관련성이 없고 좋지 못한 패턴을 훈련 데이터에서 학습하지 못하도록 하려면 가장 좋은 방법은 더 많은 훈련 데이터를 모으는 것이다.
데이터를 더 많이 모을 수 없을 때 차선책으로는 모델이 수용할 수 있는 정보의 양을 조절하거나, 저장할 수 있는 정보에 제약을 가하는 것(regularization)을 통해 중요한 패턴에 집중하고 일반화 성능을 향상시킬 수도 있다.



#### 4.4.1 네트워크 크기축소

```
과대적합을 막는 가장 단순한 방법은 모델에 있는 학습 파라미터 수를 줄이는 것이다.
모델의 용량(capacity)을 줄이는 것이다.
```


항상 유념해야 할 것은 딥러닝 모델은 훈련 데이터에 잘 맞추려는 경향이 있다는 것이다.
너무 많은 용량과 너무 적은 용량 사이의 절충점을 잘 찾는 것이 최적화와 일반화를 모두 충족하는 조건이 된다.



#### 4.4.2 가중치 규제 추가

오캄의 면도날(occam's razor) 이론 : 두개의 가정이 있다면, 더 적은 가정이 필요한 간단한 설명이 옳을 것이라는 이론
간단한 모델이 복잡한 모델보다 덜 overfitting이 일어날 가능성이 높다.

```
overfitting을 방지하기 위해 네트워크 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것이다.
이것을 weight regularization이라고 부르고 두가지가 있다.
L1 규제 : 가중치에 절댓값 비용 추가
L2 규제 : 가중치의 제곱 비용 추가(weight decay)
```

```python
from keras import regularizers

model = models.Sequential()
model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape(10000,)))
model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
```

* l2(0.001)은 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱하여 네트워크의 전체 손실에 더해진다는 의미다. 이 패널티는 훈련할 때만 추가된다.



#### 4.4.3 드랍아웃 추가

```
드롭아웃(dropout) : 규제 기법 중 가장 효과적이고 널리 사용되는 방법 중 하나.
드롭아웃을 적용하면, 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킨다.
```

어떤 층에서 [0.2,0.5,1.3,0.8,1.1]의 벡터를 출력한다고 가정하면, 드롭아웃을 적용할 경우 [0,0.5,1.3,0,1.1]으로 벡터의 일부가 무작위로 0으로 바뀐다. 

드롭아웃 비율은 0이 될 특성의 비율이다. 보통 0.2~0.5로 지정

* overfitting 을 방지하는 방법들

1. 훈련 데이터를 추가
2. 네트워크의 용량을 감소
3. 가중치 규제를 추가
4. 드롭아웃을 적용

```python
model = models.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape(10000,)))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(16,activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1,activation='sigmoid'))
```



#### 4.5 보편적인 머신러닝 작업 흐름

```
* 머신 러닝 작업의 청사진

1. 문제 정의와 데이터셋 수집
2. 성공 지표 선택
3. 평가 방법 선택
4. 데이터 준비
5. 기본보다 나은 모델 훈련하기
6. 몸집 키우기: 과대적합 모델 구축
7. 모델 규제와 하이퍼파라미터 튜닝
```



#### 4.5.1 문제 정의와 데이터셋 수집

문제 정의와 데이터셋 수집

```
- 주어진 문제를 정의

1. 입력 데이터는 무엇인가? 
2. 당면한 문제가 어떤 종류? -> 이진 분류, 다중 분류, 스칼라 회귀, 군집, 강화학습? -> 모델의 구조와 손실 함수 선택에 도움이 됨

- 가설을 세운다

1. 주어진 입력으로 출력을 예측할 수 있다고 가설을 세운다.
2. 가용한 데이터에 입력과 출력 사이의 관계를 학습하는데 충분한 정보가 있다고 가설을 세운다.
```



* 풀기 어려운 문제들 : 시간에 따라 변하는 문제(nonstationary problem)이다. 예) 주식시장의 최근 가격 변동 정볼르 가지고 주가를 예측하는건 어려움 -> 과거 가격 정보에는 예측에 활용할 정보가 많지 않기 때문
  그나마 순환성이 있는 문제(예를 들어 계절에 따른 의류 구매형태)들은 몇 년치의 데이터를 모으면 계절의 변화를 감지하는 데 충분하다.
  머신러닝은 과거를 통해 미래가 과거처럼 움직인다고 가정하고 학습한 패턴을 통해 예측하는 것이다.



#### 4.5.2 성공지표선택

성공지표 선택

```
- 성공의 지표가 모델이 최적화할 손실 함수를 선택하는 기준이 된다.
  손실함수가 직접적으로 성공과 연결되어 있어야한다.
  
- 클래스 분포가 균일한 분류 문제에서는 정확도와 ROC AUC가 일반적인 지표다.
  클래스 분포가 균일하지 않은 분류 문제에서는 정밀도와 재현율을 사용할 수 있다.
  랭킹 문제에서는 평균 정밀도를 사용할 수 있다.
  성공을 측정하는 지표는 자신만의 지표를 정의하지 말자.
```



#### 4.5.3 평가 방법 선택

평가 방법 선택

- 세 가지의 평가 방식

```
1. 홀드아웃 검증 세트 분리 : 데이터가 풍부할 때 사용한다.
2. K-겹 교차 검증 : 홀드아웃 검증을 사용하기에 샘플의 수가 너무 적을 때 사용한다.
3. 반복 K-겹 교차 검증 : 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용한다.

이중 하나를 선택하면 된다.
```

#### 4.5.4 데이터 준비

데이터 준비

- 무엇을 훈련할지와 무엇을 최적화할지, 그리고 어떻게 평가할지를 정했다면 모델에 주입할 데이터를 준비하자.

```
1. 데이터를 모델에 입력시킬 텐서로 변환한다.
2. 0~1 범위의 값 또는 -1~1 범위의 값으로 준비한다.
3. 특정마다 범위가 다르면 scaling을 한다.
4. 특성 공학을 수행할 수 있다.(특히 데이터가 적을 때)
```



#### 4.5.5 기본보다 나은 모델 훈련하기

기본보다 나은 모델 훈련하기

```
이 단계는 통계적 검정력(statistical power)을 달성하는 것이다.
아주 단순한 모델보다 나은 수준의 작은 모델을 개발한다.
클래스가 10개라면, 0.1 보다 높은 정확도를 내는 모델이 통계적 검정력을 가졌다고 할 수 있다.
클래스가 2개라면, 0.5보다 높은 정확도를 갖는 것이다.
```

이 단계에서 통계적 검정력을 달성하지 못할 경우(Bad) :

```
1번 단계에서 정의한 가설 : [주어진 입력으로 출력을 예측할 수 있다 , 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다]

가 잘못된 것일 수 있다. 그러므로 기획부터 다시 한다.
```

통계적 검정력을 달성했을 경우(Good) :

```
* 중요한 3가지의 선택을 해야한다.

1. 마지막 층의 활성화 함수(이진 분류, 다중 레이블 다중 분류 : sigmoid, 단일 레이블 다중 분류 : softmax, 임의 값에 대한 회귀 : 사용하지 않음, 0~1 사이의 회귀 : sigmoid)
2. 손실 함수(이진 분류, 다중 레이블 다중 분류 : binary_crossentropy, 단일 레이블 다중 분류 : categorical_crossentropy, 임의 값에 대한 회귀 : mse, 0~1 사이의 회귀 : mse 또는 binary_crossentropy)
3. 옵티마이저(rmsprop 또는 Adam등을 일반적으로 무난하게 사용한다)
```



#### 4.5.6 몸집키우기: 과대적합 모델 구축

몸집 키우기 : 과대적합 모델 구축

- 통계적 검정력을 가진 모델을 얻었다면, 이제 모델이 충분한 성능을 내는지 질문해 보아야 한다.
  주어진 문제를 적절히 모델링하기에 충분한 층과 파라미터가 있나?

최적화와 일반화 사이의 줄다리기를 기억하며, 적정한 capacity를 가진 모델이 경계선이라고 한다면, 그 경계선을 먼저 지나쳐 봐야 한다.

그러므로 과대적합된 모델을 우선 만든다. 

```
1. 층을 추가한다.
2. 층의 크기를 키운다.
3. 더 많은 epoch으로 훈련한다.
```

train loss, validation loss를 모니터링하며, validation loss가 증가했을 때, overfitting에 도달한 것이다.

그 이후, 규제와 모델 튜닝을 통해 이상적인 모델을 만든다.



#### 4.5.7 모델 규제와 하이퍼파라미터 튜닝

모델 규제와 하이퍼파라미터 튜닝

* 이 단계가 대부분의 시간을 차지한다.
  반복적으로 모델을 수정하고 훈련하고 validation set에서 평가한다.

적용해 볼 것들은 

```
1. 드롭아웃 적용
2. 층을 추가하거나 제거해서 다른 구조를 시도해본다
3. L1이나 L2 또는 두 가지 모두 추가한다.
4. 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도해 본다(층의 유닛 수나 옵티마이저의 학습률 등)
5. 선택적으로 특성 공학을 시도해 본다. 새로운 특성을 추가하거나 유용하지 않을 것 같은 특성을 제거한다.
```

* validation set을 통해 얻은 피드백을 활용하여 모델을 튜닝할 때마다 정보를 누설하고 있다는 점을 기억하자. 계속해서 정보를 누설하면, 점점 validation dataset에 overfitting이 일어날 것이다.

* 최종적으로 만족스러운 모델 설정을 얻었다면, trainset과 validationset을 합쳐 훈련시킨다.
  그리고 testset에서 평가한다. test set에서의 평가가 많이 나쁘다면, 
  검증과정의 신뢰성이 없거나, validation set에 overfitting 된 것이므로, 이런 경우에는 validation 방법으로 K-fold cross validation을 추천.