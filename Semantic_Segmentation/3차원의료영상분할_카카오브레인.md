### 딥러닝 엔지니어가 본 범용적 3차원 의료 영상 분할

2018/12/20 by 이수경 김일두

본문 링크 : http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI



지난 10월 서울 삼성동 코엑스 그랜드볼륨에서 열린 "2018 스마트 헬스케어 컨퍼런스" 행사에 다녀왔습니다. 저는 그 중에서도 오후에 열린 ‘딥러닝 엔지니어 관점에서 본 범용적 3차원 의료 영상 분할(generalized 3d medical image segmentation)" 세션을 듣고 왔습니다. 발표자로 나선 김일두 카카오브레인 연구원은 [아산병원 메디컬 센터 의료영상지능실현(MIRL) 연구실, 카카오브레인, 뷰노(Vuno)가 함께 참가한 챌린지](http://www.amc.seoul.kr/asan/information/journal/journalDetail.do?journalId=12307)와 문제 해결 방법론, 챌린지 참가를 통해 느낀 점에 대해 자세히 공유했습니다.

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202007107768520.jpg)[ 그림 1 ] 김일두 카카오브레인 연구원이 ‘2018 스마트 헬스케어 컨퍼런스’에서 발표하고 있다.



## 이미지 분할은?

본 글을 이해하기 위해서는 [이미지 분할(image semantic segmentation)의 개념을 우선 알아둘 필요가 있습니다](http://research.sualab.com/computer-vision/2017/11/29/image-recognition-overview-2.html). 이미지 분할은 이미지를 구성하는 개별 픽셀 분류를 목표로 합니다. 현재 보고 있는 픽셀에 해당하는 클래스(라벨) 값을 표기하는 방식으로 예측 결과물을 생성하죠. [그림 2]의 첫 번째 이미지의 풀(grass)과 소(cow)를 구분한다고 해봅시다. 소에 해당하는 픽셀 영역에는 ‘1’을, 그 외 잔디 영역에는 ‘0’을 표기합니다. 그 후 기계는 1이 표시된 곳에 파란색 마스크(mask) 씌우고, 0이 표시된 곳에 초록색 마스크를 씌워 이미지에서 소와 잔디를 명확하게 구분합니다.



[ [그림 2 ](https://jamie.shotton.org/work/research.html)] 이미지 분할에 관한 예제

그렇다면 [의료영상에서의 분할은 어떤 작업을 의미할까요?](https://www.ksiim.org/api/society/journal/download/292/3%20ksiim%20%EA%B9%80%EC%9E%A5%EC%9A%B0.pdf) 다양한 의료 영상 장비로 획득한 CT(컴퓨터단층촬영)나 MRI(자기공명영상)와 같은 진단용 의료 영상에서 장기나 종양 등의 경계선을 명확하게 그려내 이를 구분해냅니다. 과거에는 전문가가 직접 영상 분할 작업을 수행할 정도로 의료 영상이 많지 않았습니다. 하지만 첨단 기술이 발달하고 영상 장비가 생산하는 영상 정보가 폭증함에 따라 분할 자동화에 관한 필요성이 대두됐습니다. 딥러닝(deep learning)을 활용한 이미지 처리 기법이 자동 영상 분할에도 발을 뻗은 배경입니다. 딥러닝은 복잡한 의료 영상 분할을 자동화해 업무 처리 속도를 높이는 것은 물론, 의사가 놓치는 정보를 제공하며 판독 정확도를 높이는 데 도움을 주고 있습니다.

(자세히 보기 - [딥러닝을 활용한 의료영상 판독](http://www.kakaobrain.com/blog/22))

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202007489853769.png)[ [그림 3](https://towardsdatascience.com/paper-summary-h-denseunet-hybrid-densely-connected-unet-for-liver-and-tumor-segmentation-from-a47597845d37) ] 의료 영상 분할 관련 이미지 예제. H-Dense Net을 이용한 간과 종양 분할 결과. 빨간색 영역이 간, 초록색 영역이 종양이다.



## 메디컬 데커스론이란?

카카오브레인이 아산병원 연구실, 뷰노와 함께 참가한 챌린지는 [메디컬 세그먼테이션 데카스론(medical decathlon)](http://medicaldecathlon.com/)[[1\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_list_1)으로, 국제의료영상처리학회(MICCAI)가 주관하는 3차원 의료영상 분할 알고리즘 개발 대회입니다. 각 팀은 뇌, 심장, 간, 전립선, 폐 등 총 10개 장기의 의료 영상을 분할하는 속도와 정확도를 겨눴습니다. 전세계에서 약 190여개 팀이 참가한 이 대회에서 연구팀은 2등이라는 고무적인 성과를 달성했습니다.



[ 그림 4 ] 메디컬 데카스론에서는 10종의 서로 다른 의료 영상에 대한 범용적 모델을 제출해야 한다

메디컬 세그먼테이션 데카스론은 여타 다른 챌린지와는 다소 다른 문제 해결 방식을 요구합니다. 일반적인 딥러닝 챌린지는 하나의 과제를 정확하고 신속하게 수행하는 데 특화된 모델(specific model)을 요구합니다. 반면, 메디컬 데카스론에서는 10종의 서로 다른 의료 영상에 대해 일정 수준 이상의 정확도와 속도로 이미지를 나누는 범용적 모델(general model)을 요구합니다. 그 이유는 무엇일까요?

첫 번째 이유는 양질의 의료 영상 데이터를 다량 확보하기 어렵다는 데 있습니다. 희귀 사례일수록 그 데이터를 구하기가 어렵다는 현실적인 문제가 존재합니다. 의사가 의료영상에서 어느 부분이 장기이고 종양인지를 일일이 기록한 정답 데이터(ground truth data) 획득 비용이 많이 들어 다량의 학습 데이터셋 구축을 구축하기도 쉽지 않습니다.

두 번째, 클래스(범주) 불균형(class imbalance) 문제가 모델 성능에 큰 영향을 미칩니다. 정상 이미지 1000장과 암이라고 판단되는 이미지 10장을 가지고 모델을 학습시켜야 하는 상황을 가리키죠. [이런 경우 소수 범주에 속한 데이터는 다수 범주에 속한 데이터와 비교했을 때 잘못 분류될 가능성이 높습니다](http://kiise.or.kr/e_journal/2014/10/KTCP/pdf/04.pdf). 이는 기계학습 알고리즘 설계 특성상 범주의 상대적인 분포를 고려하기보다 전반의 성능 최적화에 목적을 두고 있어서 발생하는 문제입니다.

세 번째, 다중 레이블(multi-label)을 구분하는 데 모호함이 존재합니다. 단순히 정상과 비정상(예 : 암) 2가지를 판단하는 문제가 아닙니다. 여기에 더해 비정상 중에서도 암인지, 심각한 암인지, 비정상 소견을 보이나 정상인지 등 그 범주를 명확하게 따져야 합니다. 하지만 이상이 생긴 부위가 너무 작거나 명확하지 않으면 구분이 쉽지 않습니다. 전체 이미지의 크기에 비해 암 영역은 겨우 2~3개의 픽셀로 표현되는 사례가 넘쳐나기 때문입니다.

네 번째, 다중영상(multimodality image) 학습은 꽤 어려운 일에 속합니다. 다중영상은 다양한 방식으로 획득한 데이터를 의미합니다. 여기서는 MRI, CT와 같은 다양한 의료 장비로 촬영한 영상 이미지를 가리키죠. 태스크마다 데이터를 취득한 방법이 각각 다릅니다. 예를 들어, 이번 대회에서 뇌 부위 영상은 서로 다른 [MRI 기법](https://www.i-mri.org/Synapse/Data/PDFData/0040JKSMRM/jksmrm-13-9.pdf)([FLAIR, T1w, T1gd,T2w](https://www.researchgate.net/post/What_is_the_difference_between_MRI_scans_T1_T1c_T2_Flair_Is_there_another_type_of_scan))으로 획득했다면, 전립선 부위 영상은 MR 기법(T2, ADC)으로 획득했습니다. 문제는 단일영상을 입력받는 유니모달 모델과 비교했을 때 정보량이 많아져 복잡도가 커진다는 것입니다. 다중영상 A와 B가 동일한 시간대에, 같은 부위를 촬영하지 않은 상황에서 발생하는 정렬 문제(alignment issue)도 있습니다.



[ 그림 5 ] 영상 촬영 기법에 따른 영상의 종류 © [Regional brain morphometry in patients with traumatic brain injury based on acute- and chronic-phase magnetic resonance imaging - Scientific Figure on ResearchGate](https://www.researchgate.net/figure/Examples-of-MR-images-of-TBI-patients-Four-examples-of-T1-weighted-MR-images-brain_fig6_321354116)

이런 이유로 해결해야 할 과제 수는 많으나 각 과제에 속한 데이터 수가 적은 난조건 속에서도 분할 작업을 잘 수행하는 모델에 우선순위를 둔 대회 측의 의도를 엿볼 수가 있겠습니다.

챌린지 참가 방법은 다음과 같습니다. 참가팀은 8월 6일까지 공개된 간, 뇌, 허파 등 7종의 데이터로 모델을 학습시킵니다. 3D 멀티모달 데이터와 함께 데이터에 대한 설명(영상 종류와 데이터 크기, 레이블의 의미 등)도 제공됩니다. 이후에 대장암, 간 혈관, 비장암 등 3가지 데이터도 마저 공개되죠. 참가팀은 8월 31일까지 새로 주어진 3가지 데이터로 모델을 테스트한 후 결과를 제출합니다. 주최 측은 2차로 공개한 3가지 영상을 나누는 모델의 성능을 측정합니다.

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202010181121929.png)[ 표 1 ] 메디컬 데카스론에서 주어진 의료 영상 종류와 분할 대상, 그리고 훈련 및 테스트에 제공되는 데이터 수

모델의 성능 평가의 척도 중 하나는 다이스 계수(dice coefficient)입니다. 이는 일반적으로 잘 알려진 IOU(intersection over union)와 방식이 유사합니다. 아래 [그림 ?]에서 보는 것처럼 예측 마스크 영역과 실제 마스크 영역이 서로 얼마나 겹치느냐를 측정하기 때문이죠. 겹치는 영역이 1에 가까울수록 성능이 좋고(excellent), 0에 가까울수록 성능이 좋지 않다고 측정합니다(poor).



![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202029367657695.png)[ [그림 6](https://www.pyimagesearch.com/wp-content/uploads/2016/09/iou_examples.png) ] IOU에서는 예측값과 실제값이 많이 겹칠수록 좋은 성능을 낸다.





## 2단계 3D UNet로 성능을 높이다





[ [그림 7](https://arxiv.org/pdf/1611.07004.pdf) ] UNet의 구조

[영상을 분할할 때 가장 선호되는 모델 중 하나로 UNet](http://openresearch.ai/t/u-net-convolutional-networks-for-biomedical-image-segmentation/149)[[2\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_list_2)이 있습니다. UNet은 인코더-디코더 구조에 스킵 커넥션(skip connection)을 추가한 모델입니다. 영상 크기를 줄였다가(subsampling) 다시 키우면(upsampling) 정교한 픽셀 정보가 사라지게 됩니다. 이는 픽셀 단위로 조밀한 예측이 필요한 이미지 분할에선 큰 문제가 되죠. 이에 인코더에서 디코더로 중요 정보를 직접 넘겨주는 스킵커넥션을 통해 디코더 부분에서 훨씬 더 선명한 이미지를 결과를 얻게 됨에 따라 더 정확한 예측이 가능합니다. 보통 연구에서 UNet을 활용했다고 한다면, 기본 구조(인코더, 디코더, 스킵커넥션)는 유지하되, 인코더나 디코더의 구성 방식이나 그 학습 방식을 조정했다고 보시면 됩니다. 아산병원 MIRL 연구실에서도 이 부분을 조정해 성능을 올렸습니다.

아산병원은 이 UNet을 기준 모델(baseline model)로 활용한 2단계 3D UNet을 고안했습니다. 말 그대로 U-Net을 학습에 2번 적용하는 것입니다. 첫번째 단계에서는 U-Net에서는 전체 이미지 중 중요한 부분을 우선 잘라냅니다(crop). 두번째 단계에서는 U-Net은 이 오려낸 부분을 학습해 그 부위를 좀 더 자세히 분할합니다.

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202018095615227.png)[ 그림 8 ] 2단계 3D UNet의 아키텍처

UNet을 2단계에 걸쳐 적용한 이유는 무엇일까요? 첫 번째 단계에서 중요하지 않은 부분을 과감하게 제거하고 집중해야 할 부분을 솎아냄에 따라 오인식(false positive)[[3\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_list_3)을 줄이는 데 유의미한 효과를 거둘 수 있기 때문입니다. 그 결과, 연구팀은 동일한 알고리즘으로 7개 태스크를 수행하는 범용 알고리즘을 구현하는 데 성공했습니다. 김일두 연구원은 “대부분의 챌린지에서 학습을 2단계로 나눈 모델이 여러 챌린지에서도 큰 성과를 내는 추세다”며 “상위권에 포진한 팀 또한 아산병원 연구팀과 같은 방식으로 2단계나 앙상블 기법을 통해 오인식률을 크게 낮췄다"고 설명했습니다.



## “분야별 전문지식을 갖춘 기관 간의 협업이 큰 도움됐다”

물론 챌린지에 최종 제출한 모델의 아키텍처를 만드는 과정은 쉽지 않았습니다. 우선 3차원 의료 영상을 분할하는 데 적합한 것으로 보이는 다양한 형태의 아키텍처를 리서치합니다. [SE 블록](https://jayhey.github.io/deep%20learning/2018/07/18/SENet/)[[4\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_list_4)과 같은 적합한 아키텍처를 채택하고 나면, 가설을 세우고 이를 검증하는 데 많은 시간을 쏟아붓습니다. 아울러 네트워크의 깊이나 초매개변수(hyperparameter) 초기화 및 최적화 등 정규화(normalization)에 대해서도 많은 고민을 합니다.

“가장 먼저 실험의 기초선(baseline)을 잡고자 Unet 기반의 간단한 모델을 구현합니다. 그 다음, UNet 이후로 나온 최신 논문을 조사하죠. 그 결과, 인코더와 디코더의 구조를 바꾼 논문이 많음을 알 수 있었습니다. 세번째, 논문에서 제시한 변형 모델을 직접 구현해가며 실험 결과를 두 눈으로 직접 확인했습니다. 암이 있는 국소 지역의 원활한 분할을 위해 손실함수(loss function), 활성화 함수(activation function) 등을 변경해가며 모델을 훈련시켰음을 볼 수 있었죠.”

“이런 분석 결과를 토대로 모델의 약점으로 여겨지는 부분을 극복할 다양한 실험을 진행합니다. 모달리티가 다양한 만큼 입력 데이터를 전처리하는 방식에 대해서도 여러 테스트를 실시했죠. 그 결과 CT와 같은 특정 모달리티에서 잘 작동하는 전처리 방식을 적용해 성능을 개선할 수 있었습니다. 한편, 기본적인 초매개변수는 브레인 클라우드의 기능인 하이퍼파라미터 서치(hyperparameter search)를 활용했습니다. 클라우드 환경에 구축된 대규모 클러스트 상에서 실험을 다양한 방식으로 진행하면서 최적의 파라미터를 찾아주죠.(김일두 연구원)”

김일두 연구원은 분야별 전문지식을 갖추고 있는 기관과의 협업 또한 큰 도움이 되었다고 설명합니다. 김 연구원은 “의료 쪽 지식을 갖춘 아산병원과 최근 딥러닝 연구 동향에 밝으며 실제로도 문제를 해결한 경험을 갖춘 카카오브레인과 뷰노가 각자 영역에서의 전문적인 지식과 경험을 나눈 덕분에 좋은 결과를 낼 수 있었다”고 부연했습니다. 그뿐만 아니라 카카오브레인이 제공한 브레인 클라우드를 활용해 병렬적으로 여러 실험을 해볼 수 있었던 것도 긍정적인 영향을 미쳤다는 후문입니다.

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202105409539446.png)[ 그림 9 ] 브레인 클라우드의 하이퍼파라미터 서치 화면 

(자세히 보기 - [브레인 클라우드](http://www.kakaobrain.com/blog/27))



## **딥러닝 엔지니어가 제시하는 해법 "메타러닝"** 

이처럼 딥러닝을 활용해 과거에는 기술적으로 구현할 수 없거나, 구현할 수 있더라도 개발에 오랜 시간이 걸리던 작업을 상대적으로 단순한 방식으로 처리할 수 있게 됐습니다. 특정 도메인에 전문적인 지식을 갖추지 않은 사람들도 딥러닝을 활용해 우수한 성과를 내고 있죠. 더 적은 수의 인력 규모를 갖추고도 문제를 해결하고 있다는 점 또한 고무적인 일입니다.

(자세히 보기 - [유튜브 8M 챌린지 도전기](http://www.kakaobrain.com/blog/38))



물론 한계도 있습니다. 딥러닝 연구를 위해서는 그래픽처리장치(GPU), TPU(Tensor Processing Unit)[[5\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_list_5) 등의 방대한 연산 자원이 뒷받침되어야 합니다. 전문 인력의 희소성이 지나치게 높아 기술을 이에 김일두 연구원은 “우리나라를 대표하는 인공지능 회사 중 하나인 카카오브레인은 희소성이 높은 인력을 상대적으로 쉽게 구성하고 있는 편이나 사실 그렇게 하지 못하는 인공지능 회사가 국내에 더 많은 게 현실”이라고 덧붙였습니다.

문제 해결에 민첩하게 대응하지 못하는 상황도 빈번합니다. 사람이 모델의 약점을 보완하기 위한 다양한 기법을 일일이 적용해야 하죠. 프로토타입(prototype)을 만드는 데 적어도 두 달 정도는 매진하는데요, 이후 유지 보수를 할 때도 비슷한 시간이 걸립니다. 앞서 언급했듯이 적절한 성능을 내는 모델을 만드는 데 필요한 데이터 수급이 어려운 현실적인 이유도 딥러닝 연구를 더디게 만드는 요소입니다.

다시 정리하자면, 서두에서 밝힌 것처럼, 1)절대적으로 부족한 데이터, 2)클래스 불균형, 3)다중 레이블 구분의 모호함, 4)멀티모달 데이터 학습의 어려움 등 유의미한 모델 학습에 필요한 데이터 수급 또는 학습에 큰 어려움이 따릅니다. 아울러 각 태스크를 수행하는 데 적합한 모델 아키텍처 선별, 매개변수 미세조정, 데이터 전처리 및 후처리에 투입할 전문 인력이 절대적으로 부족한 상황이죠.

이에 김일두 연구원은 [지식 전이( knowledge transfer)](https://brunch.co.kr/@kakao-it/79)라는 메타 러닝(meta learning)적 관점에서 의료 영상 문제가 갖는 한계를 극복할 수 있다며 자기 생각을 밝혔습니다. 지식 전이란 기존의 지식을 전이(transfer) 또는 적응(adaptation)시키는 학습을 가리킵니다. 지식 전이에는 크게 2가지 방법론이 있습니다.

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202018276921443.png)[ 그림 10 ] © 카카오브레인

첫 번째는 바로 [다중작업 학습(multi-task learning)](https://www.edwith.org/deeplearningai3/lecture/34892/)입니다. 이는 여러 과제를 동시에 해결하는 단일 모델을 가리킵니다. 의료영상에서 이상 부위를 잘 분할하는 가중치(weight)를 얻는 것을 목표로 합니다.

![img](http://gpu-twg.kakaocdn.net/braincloud/homepage/article_image/201812202018404173906.png)[ 그림 11 ] © 카카오브레인

두 번째는 기존의 학습 방식을 뛰어넘는 메타 러닝(meta learning) 관점에서 접근하는 방식입니다. 궁극적인 목표는 적은 데이터를 짧게 학습하는 최소한의 적응(adaptation)만으로 새로운 태스크를 배울 수 있는 런 투 런(learn to learn)을 지향합니다. 말 그대로 ‘무엇인가를 배우는 법을 배운다’라는 의미입니다.

“심장 부위를 찍은 의료 영상에서 암을 찾는 법을 배운 모델이 있다고 가정해봅시다. 달리 말하면, 이 모델은 암을 가리키는 특정한 패턴을 찾아낸다고도 볼 수 있죠. 장기와 관계없이 분명한 공통적인 특징이 있다고 봅니다. 주변부 세포가 괴사해 패턴이 바뀌었거나 CT/MRI 값이 정상 분포에서 벗어나거나, 부종이 있다는 등의 특징이 대표적인 예죠. 이렇게 알게 된 특이 패턴을 새로운 태스크를 배우는 데 활용하자는 게 바로 메타 러닝입니다. 심장 부위 암 분할 지식(knowledge)을 활용해 몇 장의 사진만을 학습하기만 하더라도 위에서 암을 찾아내는 방법을 익히는 거죠. 그래서 적은 데이터와 적은 학습량으로도 높은 수준의 학습이 가능해진다고 기대해볼 수 있습니다. (김일두 연구원)”

모델을 훈련할 때 적절한 학습률(learning rate)을 갖추고자 초매개변수 설정을 미세하게 조정하는데요, 이 과정에서 상당한 노동력이 투입됩니다. 하지만 전이 학습 방식으로 문제를 푼다면 초매개변수에 덜 민감하면서도 거의 동일한 수준의 성능을 내는 모델을 만들 수 있게 됩니다. 실제로 연구팀이 메타러닝 방식을 실험에 적용해본 결과, [표 2]에서 보는 것처럼 다른 질병 부위를 학습해서 얻은 정보를 활용하면 데이터가 적은 새로운 질병 학습에 도움이 됨을 확인할 수 있었습니다.



[ 표 2 ] 기준 모델과 메타 러닝 모델을 비교했을 때 메타 러닝 모델의 성능이 더 낫다

김일두 연구원은 “사람은 자신이 지금까지 습득한 지식과 경험을 토대로 새로운 것을 배워나간다”며 “스스로 새로운 데이터와 과제를 학습하는 진화의 과정을 거쳐 다양한 과제를 해결하는 일반화된 알고리즘의 출현은 단어 그 자체가 함의하는 진짜 인공지능이라고 볼 수 있을 것”이라고 말했습니다.

마지막으로 김 연구원은 “데카스론에 같이 참가한 아산병원, 뷰노와 협업하면서 느낀 점이 많다”며 “다양한 분야에서 전문지식을 갖춘 사람들과 지속해서 협업하며 의료, 헬스케어의 발전에 기여하는 인공지능 연구를 해나가겠다”고 밝혔습니다.



**더 읽어볼 만한 글**

\- [의료와 AI 신기술의 융합](https://brunch.co.kr/@kakao-it/80)

\- [이미지 인식 문제의 개요: PASCAL VOC Challenge를 중심으로 (2)](http://research.sualab.com/computer-vision/2017/11/29/image-recognition-overview-2.html)

-[ 인공지능을 활용한 질병 조기 진단](http://www.kakaobrain.com/blog/33)

\- [딥러닝을 활용한 의료영상 판독](http://www.kakaobrain.com/blog/22)

\- [U-Net: Convolutional Networks for Biomedical Image Segmentation](http://openresearch.ai/t/u-net-convolutional-networks-for-biomedical-image-segmentation/149)

------

**참고**





[[1\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_call_1) 각 분야의 전문가(임상의사)와 데이터 과학자, 통계학자 등 다양한 분야의 사람이 팀을 이루어 주어진 시간 안에 주어진 빅데이터로부터 패턴을 찾아내고 의미를 도출하는 것을 목표로 한다



[[2\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_call_2) 2015년 Olaf Ronneberger 팀이 ‘U-Net: Convolutional Networks for Biomedical Image Segmentation’이라는 논문으로 발표한 딥러닝 학습 모델. U자형을 띄는 모양을 본따 이름이 붙여졌다.



[[3\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_call_3) 정답을 오류로 또는 오류를 정답으로 인식하는 것



[[4\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_call_4) 이미지넷(ImageNet) 2017에서 우승한 SENet이라는 논문에서 제안된 방식. 많은 이미지 정보에서 집중해야 할 이미지 위치를 알려주는 SE 블록을 추가, 성능 향상을 보였다.



[[5\]](http://www.kakaobrain.com/blog/48?fbclid=IwAR2oD1ERdzn9ewmjwn_7xq4uxiUhSIKVAnCYp811ELdejbxqmkejSyuprfI#ref_call_5) 구글에서 2016년 5월에 발표한 데이터 분석 및 딥러닝용 하드웨어



[#의료 ](http://www.kakaobrain.com/blog/tag/%EC%9D%98%EB%A3%8C)[#이미지](http://www.kakaobrain.com/blog/tag/%EC%9D%B4%EB%AF%B8%EC%A7%80)