autoencoder 사용한 이미지 분류

1. 학습 : 

   1. 재료 : 이미지
   2.  loss = tf.reduce_mean(tf.pow(inp - output, 2))
   3. 이미지를 넣으면 이미지가 똑같이 나오게 학습

2. 벡터화 : 

   1. 중간 보틀넥 레이어(conv해서 가장 feature가 추상적으로 뽑히는 레이어)의 아웃풋을 벡터로 저장

3. 평가 :

   1. reference  벡터를 불러오기

   2. query 이미지를 학습된 모델에 넣고 보틀넥에서 피쳐 벡터 추출

   3. 두 벡터의 거리 값 계산(cosine 또는 Euclidean)

   4. 쿼리 벡터하나와 레퍼런스 벡터를 비교해서 거리가 가까운 순으로 리스트에 정렬

   5. ```
      (0, ('query_0', ['refer_12', 'refer_3', 'refer_35', 'refer_87', 'refer_152', 'refer_2', ...])),
          (1, ('query_1', ['refer_2', 'refer_25', 'refer_13', 'refer_7', 'refer_64', 'refer_243', ...])),
           ...
      ```

   5. 위의 방식으로 쿼리 이미지당 가까운 레퍼런스 벡터를 나열
   6. 제출