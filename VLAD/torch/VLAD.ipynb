{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VLAD.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Sep38Zn6mWcd","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class HardTripletLoss(nn.Module):\n","    \"\"\"Hard/Hardest Triplet Loss\n","    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n","\n","    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n","    \"\"\"\n","    def __init__(self, margin=0.1, hardest=False, squared=False):\n","        \"\"\"\n","        Args:\n","            margin: margin for triplet loss\n","            hardest: If true, loss is considered only hardest triplets.\n","            squared: If true, output is the pairwise squared euclidean distance matrix.\n","                If false, output is the pairwise euclidean distance matrix.\n","        \"\"\"\n","        super(HardTripletLoss, self).__init__()\n","        self.margin = margin\n","        self.hardest = hardest\n","        self.squared = squared\n","\n","    def forward(self, embeddings, labels):\n","        \"\"\"\n","        Args:\n","            labels: labels of the batch, of size (batch_size,)\n","            embeddings: tensor of shape (batch_size, embed_dim)\n","\n","        Returns:\n","            triplet_loss: scalar tensor containing the triplet loss\n","        \"\"\"\n","        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n","\n","        if self.hardest:\n","            # Get the hardest positive pairs\n","            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n","            valid_positive_dist = pairwise_dist * mask_anchor_positive\n","            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n","\n","            # Get the hardest negative pairs\n","            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n","            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n","            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n","                    1.0 - mask_anchor_negative)\n","            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n","\n","            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n","            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n","            triplet_loss = torch.mean(triplet_loss)\n","        else:\n","            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n","            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n","\n","            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n","            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n","            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n","            # and the 2nd (batch_size, 1, batch_size)\n","            loss = anc_pos_dist - anc_neg_dist + self.margin\n","\n","            mask = _get_triplet_mask(labels).float()\n","            triplet_loss = loss * mask\n","\n","            # Remove negative losses (i.e. the easy triplets)\n","            triplet_loss = F.relu(triplet_loss)\n","\n","            # Count number of hard triplets (where triplet_loss > 0)\n","            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n","            num_hard_triplets = torch.sum(hard_triplets)\n","\n","            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n","\n","        return triplet_loss\n","\n","\n","def _pairwise_distance(x, squared=False, eps=1e-16):\n","    # Compute the 2D matrix of distances between all the embeddings.\n","\n","    cor_mat = torch.matmul(x, x.t())\n","    norm_mat = cor_mat.diag()\n","    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n","    distances = F.relu(distances)\n","\n","    if not squared:\n","        mask = torch.eq(distances, 0.0).float()\n","        distances = distances + mask * eps\n","        distances = torch.sqrt(distances)\n","        distances = distances * (1.0 - mask)\n","\n","    return distances\n","\n","\n","def _get_anchor_positive_triplet_mask(labels):\n","    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n","\n","    # Check if labels[i] == labels[j]\n","    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n","\n","    mask = indices_not_equal * labels_equal\n","\n","    return mask\n","\n","\n","def _get_anchor_negative_triplet_mask(labels):\n","    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n","\n","    # Check if labels[i] != labels[k]\n","    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n","    mask = labels_equal ^ 1\n","\n","    return mask\n","\n","\n","def _get_triplet_mask(labels):\n","    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n","\n","    A triplet (i, j, k) is valid if:\n","        - i, j, k are distinct\n","        - labels[i] == labels[j] and labels[i] != labels[k]\n","    \"\"\"\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Check that i, j and k are distinct\n","    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n","    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n","    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n","    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n","    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n","\n","    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n","    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n","    i_equal_j = torch.unsqueeze(label_equal, 2)\n","    i_equal_k = torch.unsqueeze(label_equal, 1)\n","    valid_labels = i_equal_j * (i_equal_k ^ 1)\n","\n","    mask = distinct_indices * valid_labels   # Combine the two masks\n","\n","    return mask\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDI_WhtFmXOk","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class NetVLAD(nn.Module):\n","    \"\"\"NetVLAD layer implementation\"\"\"\n","\n","    def __init__(self, num_clusters=64, dim=128, alpha=100.0,\n","                 normalize_input=True):\n","        \"\"\"\n","        Args:\n","            num_clusters : int\n","                The number of clusters\n","            dim : int\n","                Dimension of descriptors\n","            alpha : float\n","                Parameter of initialization. Larger value is harder assignment.\n","            normalize_input : bool\n","                If true, descriptor-wise L2 normalization is applied to input.\n","        \"\"\"\n","        super(NetVLAD, self).__init__()\n","        self.num_clusters = num_clusters\n","        self.dim = dim\n","        self.alpha = alpha\n","        self.normalize_input = normalize_input\n","        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n","        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n","        self._init_params()\n","\n","    def _init_params(self):\n","        self.conv.weight = nn.Parameter(\n","            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n","        )\n","        self.conv.bias = nn.Parameter(\n","            - self.alpha * self.centroids.norm(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        N, C = x.shape[:2]\n","\n","        if self.normalize_input:\n","            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n","\n","        # soft-assignment\n","        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n","        soft_assign = F.softmax(soft_assign, dim=1)\n","\n","        x_flatten = x.view(N, C, -1)\n","        \n","        # calculate residuals to each clusters\n","        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n","            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n","        residual *= soft_assign.unsqueeze(2)\n","        vlad = residual.sum(dim=-1)\n","\n","        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n","        vlad = vlad.view(x.size(0), -1)  # flatten\n","        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n","\n","        return vlad\n","\n","\n","class EmbedNet(nn.Module):\n","    def __init__(self, base_model, net_vlad):\n","        super(EmbedNet, self).__init__()\n","        self.base_model = base_model\n","        self.net_vlad = net_vlad\n","\n","    def forward(self, x):\n","        x = self.base_model(x)\n","        embedded_x = self.net_vlad(x)\n","        return embedded_x\n","\n","\n","class TripletNet(nn.Module):\n","    def __init__(self, embed_net):\n","        super(TripletNet, self).__init__()\n","        self.embed_net = embed_net\n","\n","    def forward(self, a, p, n):\n","        embedded_a = self.embed_net(a)\n","        embedded_p = self.embed_net(p)\n","        embedded_n = self.embed_net(n)\n","        return embedded_a, embedded_p, embedded_n\n","\n","    def feature_extract(self, x):\n","        return self.embed_net(x)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRy8mOJPmio7","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","from torchvision.models import resnet18\n","\n","\n","# Discard layers at the end of base network\n","encoder = resnet18(pretrained=True)\n","base_model = nn.Sequential(\n","    encoder.conv1,\n","    encoder.bn1,\n","    encoder.relu,\n","    encoder.maxpool,\n","    encoder.layer1,\n","    encoder.layer2,\n","    encoder.layer3,\n","    encoder.layer4,\n",")\n","dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n","\n","# Define model for embedding\n","net_vlad = NetVLAD(num_clusters=32, dim=dim, alpha=1.0)\n","model = EmbedNet(base_model, net_vlad).cuda()\n","\n","# Define loss\n","criterion = HardTripletLoss(margin=0.1).cuda()\n","\n","# This is just toy example. Typically, the number of samples in each classes are 4.\n","labels = torch.randint(0, 10, (40, )).cuda()\n","x = torch.rand(40, 3, 128, 128).cuda()\n","output = model(x)\n","\n","triplet_loss = criterion(output, labels)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s41tHCIKmpTe","colab_type":"code","colab":{}},"source":["output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19NTHZWNo24r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"5d5d9bce-f902-4f10-ad40-59d3276c999f","executionInfo":{"status":"ok","timestamp":1557806043057,"user_tz":-540,"elapsed":990,"user":{"displayName":"SOFT HI","photoUrl":"https://lh3.googleusercontent.com/-F3CCHlI0HDc/AAAAAAAAAAI/AAAAAAAAAAw/4rqV-_mvMdg/s64/photo.jpg","userId":"13903510717352952256"}}},"source":["triplet_loss"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.1001, device='cuda:0', grad_fn=<DivBackward0>)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"NE0bFCx2o4wY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}